import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.model_selection import GridSearchCV

# Load the dataset
file_path = '/Users/judithmashudi/Downloads/filtered_features_df (1).csv'
df = pd.read_csv(file_path)

# Check for missing values
print(df.isnull().sum())

# Define features and target
target = 'genre'
X = df.drop(columns=[target])
y = df[target]

# Identify categorical features
categorical_features = X.select_dtypes(include=['object']).columns.tolist()

# Preprocess categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns.tolist())
    ])

# Split the data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Create a preprocessing and training pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(random_state=42))
])

# Perform hyperparameter tuning using GridSearchCV with validation set
param_grid = {
    'classifier__max_depth': [5, 10, 15],
    'classifier__min_samples_split': [10, 20, 30],
    'classifier__min_samples_leaf': [4, 6, 8]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Best parameters found by GridSearchCV
print(f"Best parameters: {grid_search.best_params_}")

# Train the classifier with best parameters
best_pipeline = grid_search.best_estimator_

# Evaluate using validation set
y_val_pred = best_pipeline.predict(X_val)
val_accuracy = accuracy_score(y_val, y_val_pred)
val_report = classification_report(y_val, y_val_pred)

print(f"Validation Accuracy: {val_accuracy:.2f}")
print(f"Validation Classification Report:\n{val_report}")

# Evaluate using cross-validation on the training set
cv_scores = cross_val_score(best_pipeline, X_train, y_train, cv=5, scoring='f1_weighted')

# Train the classifier on the full training set
best_pipeline.fit(X_train, y_train)

# Make predictions on the test set
y_test_pred = best_pipeline.predict(X_test)

# Evaluate the classifier on the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
test_report = classification_report(y_test, y_test_pred)

print(f"Cross-Validation F1 Scores: {cv_scores}")
print(f"Mean Cross-Validation F1 Score: {cv_scores.mean():.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")
print(f"Test Classification Report:\n{test_report}")
